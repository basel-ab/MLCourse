{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOloPu5Ujkg519TYeZNaTBI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanadv/MLCourse/blob/main/Lesson_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VwrubDz5cS2",
        "outputId": "18fab2d7-536e-496f-e154-99424cf57c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[X1 = Yes]\n",
            " [X1 = Yes]\n",
            "  [Bird]\n",
            "  [Bird]\n",
            " [X2 = Yes]\n",
            "  [X1 = No]\n",
            "   [Fish]\n",
            "   [Fish]\n",
            "  [X1 = No]\n",
            "   [Mammal]\n",
            "   [Mammal]\n",
            "Predicted class: Fish\n"
          ]
        }
      ],
      "source": [
        "# 4.1 Dicision Tree with Gini Impurity\n",
        "# Sample dataset: [Feature1: Can Fly, Feature2: Has Fins, Label: Class]\n",
        "data = [\n",
        "    [\"Yes\", \"No\", \"Bird\"],\n",
        "    [\"No\", \"Yes\", \"Fish\"],\n",
        "    [\"No\", \"No\", \"Mammal\"],\n",
        "    [\"No\", \"Yes\", \"Fish\"],\n",
        "    [\"Yes\", \"No\", \"Bird\"],\n",
        "    [\"No\", \"No\", \"Mammal\"],\n",
        "    [\"Yes\", \"No\", \"Bird\"],\n",
        "    [\"No\", \"Yes\", \"Fish\"],\n",
        "    [\"No\", \"No\", \"Mammal\"]\n",
        "]\n",
        "def gini_impurity(groups, classes):\n",
        "    # Count all samples at split point\n",
        "    n_instances = float(sum([len(group) for group in groups]))\n",
        "    # Sum weighted Gini impurity for each group\n",
        "    gini = 0.0\n",
        "    for group in groups:\n",
        "        size = float(len(group))\n",
        "        if size == 0:  # avoid division by zero\n",
        "            continue\n",
        "        score = 0.0\n",
        "        # Score the group based on the score for each class\n",
        "        for class_val in classes:\n",
        "            p = [row[-1] for row in group].count(class_val) / size\n",
        "            score += p * p\n",
        "        # Weight the group score by its relative size\n",
        "        gini += (1.0 - score) * (size / n_instances)\n",
        "    return gini\n",
        "\n",
        "def test_split(index, value, dataset):\n",
        "    left, right = list(), list()\n",
        "    for row in dataset:\n",
        "        if row[index] == value:\n",
        "            left.append(row)\n",
        "        else:\n",
        "            right.append(row)\n",
        "    return left, right\n",
        "\n",
        "def get_split(dataset):\n",
        "    class_values = list(set(row[-1] for row in dataset))\n",
        "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "    for index in range(len(dataset[0])-1):\n",
        "        for row in dataset:\n",
        "            groups = test_split(index, row[index], dataset)\n",
        "            gini = gini_impurity(groups, class_values)\n",
        "            if gini < b_score:\n",
        "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
        "\n",
        "def to_terminal(group):\n",
        "    outcomes = [row[-1] for row in group]\n",
        "    return max(set(outcomes), key=outcomes.count)\n",
        "\n",
        "def split(node, max_depth, min_size, depth):\n",
        "    left, right = node['groups']\n",
        "    del(node['groups'])\n",
        "    # check for a no split\n",
        "    if not left or not right:\n",
        "        node['left'] = node['right'] = to_terminal(left + right)\n",
        "        return\n",
        "    # check for max depth\n",
        "    if depth >= max_depth:\n",
        "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
        "        return\n",
        "    # process left child\n",
        "    if len(left) <= min_size:\n",
        "        node['left'] = to_terminal(left)\n",
        "    else:\n",
        "        node['left'] = get_split(left)\n",
        "        split(node['left'], max_depth, min_size, depth+1)\n",
        "    # process right child\n",
        "    if len(right) <= min_size:\n",
        "        node['right'] = to_terminal(right)\n",
        "    else:\n",
        "        node['right'] = get_split(right)\n",
        "        split(node['right'], max_depth, min_size, depth+1)\n",
        "\n",
        "def build_tree(train, max_depth, min_size):\n",
        "    root = get_split(train)\n",
        "    split(root, max_depth, min_size, 1)\n",
        "    return root\n",
        "\n",
        "def print_tree(node, depth=0):\n",
        "    if isinstance(node, dict):\n",
        "        print('%s[X%d = %s]' % ((depth*' ', node['index']+1, node['value'])))\n",
        "        print_tree(node['left'], depth+1)\n",
        "        print_tree(node['right'], depth+1)\n",
        "    else:\n",
        "        print('%s[%s]' % ((depth*' ',node)))\n",
        "\n",
        "# Build and print the decision tree\n",
        "tree = build_tree(data, max_depth=3, min_size=1)\n",
        "print_tree(tree)\n",
        "\n",
        "def predict(node, row):\n",
        "    if row[node['index']] == node['value']:\n",
        "        if isinstance(node['left'], dict):\n",
        "            return predict(node['left'], row)\n",
        "        else:\n",
        "            return node['left']\n",
        "    else:\n",
        "        if isinstance(node['right'], dict):\n",
        "            return predict(node['right'], row)\n",
        "        else:\n",
        "            return node['right']\n",
        "\n",
        "# Example of making a prediction\n",
        "sample = [\"No\", \"Yes\", \"Bird\"]  # New sample for prediction\n",
        "prediction = predict(tree, sample)\n",
        "print('Predicted class: %s' % prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dataset\n",
        "The dataset consists of examples with two features (\"Can Fly\", \"Has Fins\") and a label indicating the class (\"Bird\", \"Fish\", \"Mammal\").\n",
        "\n",
        "`gini_impurity(groups, classes)`\n",
        "This function calculates the Gini impurity for a set of groups. Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it were randomly labeled according to the distribution of labels in the subset.\n",
        "- `groups`: A list of groups where each group contains rows from the dataset that have been split based on a feature value.\n",
        "- `classes`: A list of unique class labels in the dataset.\n",
        "- It calculates the weighted Gini impurity for each group and sums them to get the overall Gini impurity for the split.\n",
        "\n",
        "`test_split(index, value, dataset)`\n",
        "This function tests a potential split on the dataset based on a given feature index and feature value.\n",
        "- `index`: The index of the feature to split on.\n",
        "- `value`: The value of the feature to split by.\n",
        "- It divides the dataset into two groups: one where the feature value matches the split value and one where it doesn't.\n",
        "\n",
        "`get_split(dataset)`\n",
        "This function iterates over each feature and its unique values to find the best split, measured by the lowest Gini impurity.\n",
        "- It returns a dictionary containing the index of the best feature to split on, the value of that feature for the split, and the two groups of data created by the split.\n",
        "\n",
        "`to_terminal(group)`\n",
        "This function creates a terminal node predicted output. It selects the most common output value among a set of rows and uses this as the prediction for the terminal node.\n",
        "- `group`: A subset of the dataset that has been split down to a leaf in the tree.\n",
        "\n",
        "`split(node, max_depth, min_size, depth)`\n",
        "This function recursively splits nodes until the tree reaches a specified maximum depth or the nodes are sufficiently pure (as measured by `min_size`, the minimum number of samples a node must have to consider splitting further).\n",
        "- `node`: The current node to split.\n",
        "- `max_depth`: The maximum depth of the tree.\n",
        "- `min_size`: The minimum size of a node.\n",
        "- `depth`: The current depth of the node in the tree.\n",
        "\n",
        "`build_tree(train, max_depth, min_size)`\n",
        "This function builds the decision tree using the training data.\n",
        "- `train`: The training dataset.\n",
        "- It initializes the root of the tree using the best split and recursively splits each branch using the `split` function.\n",
        "\n",
        "`print_tree(node, depth=0)`\n",
        "This function prints the tree structure, showing splits on features and the resulting predictions at terminal nodes.\n",
        "- `node`: The current node in the tree to print.\n",
        "- `depth`: The current depth of the node in the tree, used for indentation.\n",
        "\n",
        "`predict(node, row)`\n",
        "This function makes a prediction for a given row of data by traversing the tree and following the splits until reaching a terminal node.\n",
        "- `node`: The current node in the tree.\n",
        "- `row`: The row of data to predict.\n",
        "\n",
        "Execution Example\n",
        "The tree is built and printed using the sample dataset. Then, the `predict` function is used to classify a new sample. The output indicates the predicted class based on the constructed decision tree.\n",
        "\n",
        "This implementation is a basic example of how decision trees work. It highlights key concepts like splitting based on Gini impurity and recursively building the tree. This example is designed for educational purposes and might not be efficient or suitable for production use compared to optimized libraries like scikit-learn."
      ],
      "metadata": {
        "id": "maxqjyQ066bp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2fM6UMm465Qn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}